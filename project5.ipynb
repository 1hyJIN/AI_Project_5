{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64724fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, BertForMaskedLM, BertConfig, BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81dd1093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "with open('./train.txt', 'r') as f:\n",
    "  lines = f.readlines()\n",
    "\n",
    "train_set = []\n",
    "\n",
    "for line in lines[1:]:\n",
    "  data = {}\n",
    "  line = line.replace('\\n','')\n",
    "  guid, tag = line.split(',')\n",
    "  if tag == 'positive':\n",
    "    label = 0\n",
    "  elif tag == 'neutral':\n",
    "    label = 1\n",
    "  else:\n",
    "    label = 2\n",
    "  data['guid'] = guid\n",
    "  data['label'] = label\n",
    "  train_set.append(data)\n",
    "\n",
    "print(len(train_set)) # 4000\n",
    "# print(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d3c5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./test_without_label.txt', 'r') as f:\n",
    "  lines = f.readlines()\n",
    "\n",
    "test_set = []\n",
    "for line in lines[1:]:\n",
    "  data = {}\n",
    "  data['guid'] = line.split(',')[0]\n",
    "  test_set.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d617f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(dataset):\n",
    "  for data in dataset:\n",
    "    guid = data['guid']\n",
    "    image_path = './data/' + guid + '.jpg'\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    array = np.array(image.resize((224, 224)))\n",
    "    data['image'] = array.reshape((3, 224, 224))\n",
    "\n",
    "    text_path = './data/' + guid + '.txt'\n",
    "    f = open(text_path, 'r', errors='ignore')\n",
    "    lines = f.readlines()\n",
    "    # print(lines)\n",
    "    text = ''\n",
    "    for line in lines:\n",
    "      text += line\n",
    "    data['text'] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0820ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_process(train_set)\n",
    "data_process(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5eb4d089",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_num = 3500\n",
    "valid_set_num = 500\n",
    "train_set, valid_set = random_split(train_set, [train_set_num, valid_set_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "588fb580",
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = ['ResNet50', 'ResNet101','ResNet152']\n",
    "\n",
    "def Conv1(in_planes, places, stride=2):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels=in_planes,out_channels=places,kernel_size=7,stride=stride,padding=3, bias=False),\n",
    "        nn.BatchNorm2d(places),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "    )\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self,in_places,places, stride=1,downsampling=False, expansion = 4):\n",
    "        super(Bottleneck,self).__init__()\n",
    "        self.expansion = expansion\n",
    "        self.downsampling = downsampling\n",
    "\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_places,out_channels=places,kernel_size=1,stride=1, bias=False),\n",
    "            nn.BatchNorm2d(places),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=places, out_channels=places, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(places),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=places, out_channels=places*self.expansion, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(places*self.expansion),\n",
    "        )\n",
    "\n",
    "        if self.downsampling:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_places, out_channels=places*self.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(places*self.expansion)\n",
    "            )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.bottleneck(x)\n",
    "\n",
    "        if self.downsampling:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self,blocks, num_classes=3, expansion = 4):\n",
    "        super(ResNet,self).__init__()\n",
    "        self.expansion = expansion\n",
    "\n",
    "        self.conv1 = Conv1(in_planes = 3, places= 64)\n",
    "\n",
    "        self.layer1 = self.make_layer(in_places = 64, places= 64, block=blocks[0], stride=1)\n",
    "        self.layer2 = self.make_layer(in_places = 256,places=128, block=blocks[1], stride=2)\n",
    "        self.layer3 = self.make_layer(in_places=512,places=256, block=blocks[2], stride=2)\n",
    "        self.layer4 = self.make_layer(in_places=1024,places=512, block=blocks[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(2048,num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def make_layer(self, in_places, places, block, stride):\n",
    "        layers = []\n",
    "        layers.append(Bottleneck(in_places, places,stride, downsampling =True))\n",
    "        for i in range(1, block):\n",
    "            layers.append(Bottleneck(places*self.expansion, places))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet([3, 4, 6, 3])\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet([3, 4, 23, 3])\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet([3, 8, 36, 3])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8673e4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train = []\n",
    "image_train_labels = []\n",
    "image_valid = []\n",
    "image_valid_labels = []\n",
    "\n",
    "for data in train_set:\n",
    "  image_train.append(data['image'])\n",
    "  image_train_labels.append(data['label'])\n",
    "\n",
    "for data in valid_set:\n",
    "  image_valid.append(data['image'])\n",
    "  image_valid_labels.append(data['label'])\n",
    "\n",
    "image_train = torch.from_numpy(np.array(image_train))\n",
    "image_train_labels = torch.from_numpy(np.array(image_train_labels))\n",
    "image_valid = torch.from_numpy(np.array(image_valid))\n",
    "image_valid_labels = torch.from_numpy(np.array(image_valid_labels))\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(image_train, image_train_labels), batch_size=100, shuffle=True)\n",
    "valid_loader = DataLoader(TensorDataset(image_valid, image_valid_labels), batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c5b248f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea324dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    #model = torchvision.models.resnet50()\n",
    "    image_model = ResNet50()\n",
    "    image_model.to(device)\n",
    "\n",
    "epoch_num = 10\n",
    "learning_rate = 1e-5\n",
    "total_step = epoch_num * len(train_loader)\n",
    "\n",
    "optimizer = AdamW(image_model.parameters(), lr=learning_rate, eps=1e-8)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.1*total_step, num_training_steps=total_step)\n",
    "\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be1b1cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1  loss: 1.237\n",
      "epoch: 2  loss: 0.933\n",
      "epoch: 3  loss: 0.893\n",
      "epoch: 4  loss: 0.888\n",
      "epoch: 5  loss: 0.885\n",
      "epoch: 6  loss: 0.882\n",
      "epoch: 7  loss: 0.884\n",
      "epoch: 8  loss: 0.879\n",
      "epoch: 9  loss: 0.877\n",
      "epoch: 10  loss: 0.875\n",
      "Training Accuracy: 56.600%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch_num):\n",
    "  running_loss = 0\n",
    "  for i, data in enumerate(train_loader):\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.float()\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    # print(inputs.shape)\n",
    "    outputs = image_model(inputs)\n",
    "    # print(outputs.shape)\n",
    "    loss = criterion(outputs, labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    running_loss += loss.item()\n",
    "  print('epoch: %d  loss: %.3f' % (epoch+1, running_loss / 35))\n",
    "  running_loss = 0\n",
    "\n",
    "correct_num = 0\n",
    "total_num = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "  for data in valid_loader:\n",
    "    inputs, answers = data\n",
    "    inputs = inputs.float()\n",
    "    inputs = inputs.to(device)\n",
    "    answers = answers.to(device)\n",
    "    outputs = image_model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    for i in range(len(predicted.tolist())):\n",
    "      total_num += answers.size(0)\n",
    "      correct_num += (predicted == answers).sum().item()\n",
    "\n",
    "print('Training Accuracy: %.3f%%' % (100 * correct_num / total_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "588c0d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./bert_chinese were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "checkpoint = './bert_chinese'\n",
    "tokenizer = BertTokenizer.from_pretrained(checkpoint)\n",
    "config = BertConfig.from_pretrained(checkpoint, output_hidden_states = True, output_attentions=True)\n",
    "assert config.output_hidden_states == True\n",
    "assert config.output_attentions == True\n",
    "# bert_model = BertModel.from_pretrained(checkpoint, config=config)\n",
    "bert_model = BertForMaskedLM.from_pretrained(checkpoint, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f76e1b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(TextClassifier, self).__init__()\n",
    "    self.model = bert_model\n",
    "    self.model = self.model.to(device)\n",
    "    self.dropout = nn.Dropout(0)\n",
    "    # self.model.to(device)\n",
    "    # self.fc = nn.Linear(768, 3)\n",
    "    self.fc = nn.Linear(98304, 3)\n",
    "  \n",
    "  def forward(self, x, attn_mask=None):\n",
    "    x = x.to(device)\n",
    "    attn_mask = attn_mask.to(device)\n",
    "    output = self.model(x, attention_mask=attn_mask)\n",
    "    output = output.hidden_states[-1]\n",
    "    # print(output.shape)\n",
    "    # output = output.logits\n",
    "    \n",
    "    output = torch.flatten(output, 1)\n",
    "    output = self.fc(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c4e2c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = []\n",
    "text_valid = []\n",
    "\n",
    "for data in train_set:\n",
    "  tokenized_text = tokenizer(data['text'], max_length=128, padding='max_length', truncation=True)\n",
    "  # tokenized_text['input_ids'] = torch.from_numpy(np.array(tokenized_text['input_ids']))\n",
    "  tokenized_text['label'] = data['label']\n",
    "  text_train.append(tokenized_text)\n",
    "\n",
    "for data in valid_set:\n",
    "  tokenized_text = tokenizer(data['text'], max_length=128, padding='max_length', truncation=True)\n",
    "  tokenized_text['label'] = data['label']\n",
    "  text_valid.append(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c053ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "  def __init__(self, data):\n",
    "    super(TextDataset, self).__init__()\n",
    "    self.data = data\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    input_ids = self.data[idx]['input_ids']\n",
    "    attn_mask = self.data[idx]['attention_mask']\n",
    "    label = self.data[idx]['label']\n",
    "    return input_ids, attn_mask, label\n",
    "\n",
    "train_loader = DataLoader(TextDataset(text_train), batch_size=25, shuffle=True)\n",
    "valid_loader = DataLoader(TextDataset(text_valid), batch_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a1c64d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model = TextClassifier()\n",
    "text_model.to(device)\n",
    "# classifier.model.to(device)\n",
    "\n",
    "epoch_num = 20\n",
    "learning_rate = 1e-5\n",
    "total_step = epoch_num * len(train_loader)\n",
    "\n",
    "optimizer = AdamW(text_model.parameters(), lr=learning_rate, eps=1e-8)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.1*total_step, num_training_steps=total_step)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1111048e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1  loss: 0.915\n",
      "epoch: 2  loss: 0.800\n",
      "epoch: 3  loss: 0.605\n",
      "epoch: 4  loss: 0.317\n",
      "epoch: 5  loss: 0.147\n",
      "epoch: 6  loss: 0.097\n",
      "epoch: 7  loss: 0.083\n",
      "epoch: 8  loss: 0.060\n",
      "epoch: 9  loss: 0.056\n",
      "epoch: 10  loss: 0.047\n",
      "epoch: 11  loss: 0.044\n",
      "epoch: 12  loss: 0.040\n",
      "epoch: 13  loss: 0.040\n",
      "epoch: 14  loss: 0.038\n",
      "epoch: 15  loss: 0.035\n",
      "epoch: 16  loss: 0.033\n",
      "epoch: 17  loss: 0.031\n",
      "epoch: 18  loss: 0.031\n",
      "epoch: 19  loss: 0.028\n",
      "epoch: 20  loss: 0.027\n",
      "Training Accuracy: 61.400%\n"
     ]
    }
   ],
   "source": [
    "# classifier.train()\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "  running_loss = 0\n",
    "  for i, data in enumerate(train_loader):\n",
    "    input_ids, attn_mask, labels = data\n",
    "    input_ids = torch.tensor([item.numpy() for item in input_ids])\n",
    "    attn_mask = torch.tensor([item.numpy() for item in attn_mask])\n",
    "    input_ids = input_ids.T\n",
    "    attn_mask = attn_mask.T\n",
    "    # labels = torch.tensor([item.numpy() for item in labels])\n",
    "    input_ids = input_ids.to(device)\n",
    "    attn_mask = attn_mask.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # print(input_ids.shape)\n",
    "    # print(attn_mask.shape)\n",
    "\n",
    "    outputs = text_model(input_ids, attn_mask)\n",
    "    # outputs = bert_model(input_ids)\n",
    "\n",
    "    loss = criterion(outputs, labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    running_loss += loss.item()\n",
    "  print('epoch: %d  loss: %.3f' % (epoch+1, running_loss/140))\n",
    "  running_loss = 0\n",
    "    \n",
    "\n",
    "correct_num = 0\n",
    "total_num = 0\n",
    "with torch.no_grad():\n",
    "  for data in valid_loader:\n",
    "    input_ids, attn_mask, labels = data\n",
    "    input_ids = torch.tensor([item.numpy() for item in input_ids])\n",
    "    input_ids = input_ids.T\n",
    "    attn_mask = torch.tensor([item.numpy() for item in attn_mask])\n",
    "    attn_mask = attn_mask.T\n",
    "    input_ids = input_ids.to(device)\n",
    "    attn_mask = attn_mask.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    outputs = text_model(input_ids, attn_mask)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    for i in range(len(predicted.tolist())):\n",
    "      total_num += labels.size(0)\n",
    "      correct_num += (predicted == labels).sum().item()\n",
    "\n",
    "print('Training Accuracy: %.3f%%' % (100 * correct_num / total_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "df1874a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalDataset(Dataset):\n",
    "  def __init__(self, data):\n",
    "    super(MultimodalDataset, self).__init__()\n",
    "    self.data = data\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    guid = self.data[idx]['guid']\n",
    "    input_ids = torch.tensor(self.data[idx]['input_ids'])\n",
    "    attn_mask = torch.tensor(self.data[idx]['attn_mask'])\n",
    "    image = torch.tensor(self.data[idx]['image'])\n",
    "    label = self.data[idx].get('label')\n",
    "    if label is None:\n",
    "      label = -100\n",
    "    label = torch.tensor(label)\n",
    "    return guid, input_ids, attn_mask, image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c4b3f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_process(dataset):\n",
    "  for data in dataset:\n",
    "    tokenized_text = tokenizer(data['text'], max_length=128, padding='max_length', truncation=True)\n",
    "    data['input_ids'] = tokenized_text['input_ids']\n",
    "    data['attn_mask'] = tokenized_text['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "53246a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_process(train_set)\n",
    "dataset_process(valid_set)\n",
    "dataset_process(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "500f7ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(MultimodalDataset(train_set), batch_size=25, shuffle=True)\n",
    "valid_loader = DataLoader(MultimodalDataset(valid_set), batch_size=25)\n",
    "test_loader = DataLoader(MultimodalDataset(test_set), batch_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fc5c1194",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalModel(nn.Module):\n",
    "  def __init__(self, image_model, text_model, output_features, image_weight=0.5, text_weight=0.5):\n",
    "    super(MultimodalModel, self).__init__()\n",
    "    self.image_model = image_model\n",
    "    self.text_model = text_model\n",
    "    # 将最后的全连接层删除\n",
    "    self.image_model.fc = nn.Sequential()  # (batch_num, 512)\n",
    "    self.text_model.fc = nn.Sequential()    # (batch_num, 768)\n",
    "    # 文本特征向量和图片特征向量的权重, 默认均为0.5\n",
    "    self.image_weight = image_weight\n",
    "    self.text_weight = text_weight\n",
    "    self.fc1 = nn.Linear((4*512+768*128), output_features)\n",
    "    self.fc2 = nn.Linear(output_features, 3)\n",
    "\n",
    "  def forward(self, input_ids, attn_mask, image):\n",
    "    image_output = self.image_model(image)\n",
    "    text_output = self.text_model(input_ids, attn_mask)\n",
    "    output = torch.cat([image_output, text_output], dim=-1)\n",
    "    output = self.fc1(output)\n",
    "    output = self.fc2(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a797585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_model = MultimodalModel(image_model=image_model, text_model=text_model, output_features=100, image_weight=0.5, text_weight=0.5)\n",
    "multimodal_model.to(device)\n",
    "\n",
    "epoch_num = 10\n",
    "learning_rate = 1e-5\n",
    "total_step = epoch_num * len(train_loader)\n",
    "\n",
    "optimizer = AdamW(multimodal_model.parameters(), lr=learning_rate, eps=1e-8)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.1*total_step, num_training_steps=total_step)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e80a431a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1  loss: 0.203\n",
      "epoch: 2  loss: 0.118\n",
      "epoch: 3  loss: 0.099\n",
      "epoch: 4  loss: 0.066\n",
      "epoch: 5  loss: 0.065\n",
      "epoch: 6  loss: 0.044\n",
      "epoch: 7  loss: 0.036\n",
      "epoch: 8  loss: 0.033\n",
      "epoch: 9  loss: 0.030\n",
      "epoch: 10  loss: 0.028\n",
      "Training Accuracy: 60.400%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch_num):\n",
    "  running_loss = 0\n",
    "  for i, data in enumerate(train_loader):\n",
    "    _, input_ids, attn_mask, image, label = data\n",
    "    input_ids = input_ids.to(device)\n",
    "    attn_mask = attn_mask.to(device)\n",
    "    image = image.to(device)\n",
    "    image = image.float()\n",
    "    label = label.to(device)\n",
    "\n",
    "    outputs = multimodal_model(input_ids=input_ids, attn_mask=attn_mask, image=image)\n",
    "    # print(outputs.shape)\n",
    "    loss = criterion(outputs, label)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "  print('epoch: %d  loss: %.3f' % (epoch+1, running_loss/140))\n",
    "  running_loss = 0\n",
    "    \n",
    "    \n",
    "correct_num = 0\n",
    "total_num = 0\n",
    "with torch.no_grad():\n",
    "  for data in valid_loader:\n",
    "    _, input_ids, attn_mask, image, label = data\n",
    "    input_ids = input_ids.to(device)\n",
    "    attn_mask = attn_mask.to(device)\n",
    "    image = image.to(device)\n",
    "    image = image.float()\n",
    "    label = label.to(device)\n",
    "    \n",
    "    outputs = multimodal_model(input_ids=input_ids, attn_mask=attn_mask, image=image)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    for i in range(len(predicted.tolist())):\n",
    "      total_num += label.size(0)\n",
    "      correct_num += (predicted == label).sum().item()\n",
    "\n",
    "print('Training Accuracy: %.3f%%' % (100 * correct_num / total_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6ebadcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {}\n",
    "with torch.no_grad():\n",
    "  for data in test_loader:\n",
    "    guid, input_ids, attn_mask, image, label = data\n",
    "    input_ids = input_ids.to(device)\n",
    "    attn_mask = attn_mask.to(device)\n",
    "    image = image.to(device)\n",
    "    image = image.float()\n",
    "    label = label.to(device)\n",
    "    \n",
    "    outputs = multimodal_model(input_ids=input_ids, attn_mask=attn_mask, image=image)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predicted = predicted.tolist()\n",
    "    for i in range(len(predicted)):\n",
    "      id = guid[i]\n",
    "      test_dict[id] = predicted[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c241b697",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./test_without_label.txt', 'r') as f:\n",
    "  lines = f.readlines()\n",
    "\n",
    "f1 = open('./test.txt', 'w')\n",
    "f1.write(lines[0])\n",
    "\n",
    "for line in lines[1:]:\n",
    "  # print(line)\n",
    "  guid = line.split(',')[0]\n",
    "  f1.write(guid)\n",
    "  f1.write(',')\n",
    "  label = test_dict[guid]\n",
    "  if label == 0:\n",
    "    f1.write('positive\\n')\n",
    "  elif label == 1:\n",
    "    f1.write('neutral\\n')\n",
    "  else:\n",
    "    f1.write('negative\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31b59d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35b6cde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
